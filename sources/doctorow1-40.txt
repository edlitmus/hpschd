Editor’s Note: Surveillance capitalism
is everywhere. But it’s not the result
of some wrong turn or a rogue abuse of
corporate power — it’s the system
working as intended. This is the subject
of Cory Doctorow’s new book, which we’re
thrilled to publish in whole here on
OneZero. This is how to destroy
surveillance capitalism.  The net of a
thousand lies The most surprising thing
about the rebirth of flat Earthers in
the 21st century is just how widespread
the evidence against them is. You can
understand how, centuries ago, people
who’d never gained a high-enough vantage
point from which to see the Earth’s
curvature might come to the commonsense
belief that the flat-seeming Earth was,
indeed, flat.  But today, when
elementary schools routinely dangle
GoPro cameras from balloons and loft
them high enough to photograph the
Earth’s curve — to say nothing of the
unexceptional sight of the curved Earth
from an airplane window — it takes a
heroic effort to maintain the belief
that the world is flat.  Likewise for
white nationalism and eugenics: In an
age where you can become a computational
genomics datapoint by swabbing your
cheek and mailing it to a
gene-sequencing company along with a
modest sum of money, “race science” has
never been easier to refute.  We are
living through a golden age of both
readily available facts and denial of
those facts. Terrible ideas that have
lingered on the fringes for decades or
even centuries have gone mainstream
seemingly overnight.  When an obscure
idea gains currency, there are only two
things that can explain its ascendance:
Either the person expressing that idea
has gotten a lot better at stating their
case, or the proposition has become
harder to deny in the face of mounting
evidence. In other words, if we want
people to take climate change seriously,
we can get a bunch of Greta Thunbergs to
make eloquent, passionate arguments from
podiums, winning our hearts and minds,
or we can wait for flood, fire, broiling
sun, and pandemics to make the case for
us. In practice, we’ll probably have to
do some of both: The more we’re boiling
and burning and drowning and wasting
away, the easier it will be for the
Greta Thunbergs of the world to convince
us.  The arguments for ridiculous
beliefs in odious conspiracies like
anti-vaccination, climate denial, a flat
Earth, and eugenics are no better than
they were a generation ago. Indeed,
they’re worse because they are being
pitched to people who have at least a
background awareness of the refuting
facts.  Anti-vax has been around since
the first vaccines, but the early
anti-vaxxers were pitching people who
were less equipped to understand even
the most basic ideas from microbiology,
and moreover, those people had not
witnessed the extermination of
mass-murdering diseases like polio,
smallpox, and measles. Today’s
anti-vaxxers are no more eloquent than
their forebears, and they have a much
harder job.  So can these far-fetched
conspiracy theorists really be
succeeding on the basis of superior
arguments?  Some people think so. Today,
there is a widespread belief that
machine learning and commercial
surveillance can turn even the most
fumble-tongued conspiracy theorist into
a svengali who can warp your perceptions
and win your belief by locating
vulnerable people and then pitching them
with A.I.-refined arguments that bypass
their rational faculties and turn
everyday people into flat Earthers,
anti-vaxxers, or even Nazis. When the
RAND Corporation blames Facebook for
“radicalization” and when Facebook’s
role in spreading coronavirus
misinformation is blamed on its
algorithm, the implicit message is that
machine learning and surveillance are
causing the changes in our consensus
about what’s true.  After all, in a
world where sprawling and incoherent
conspiracy theories like Pizzagate and
its successor, QAnon, have widespread
followings, something must be afoot.
But what if there’s another explanation?
What if it’s the material circumstances,
and not the arguments, that are making
the difference for these conspiracy
pitchmen? What if the trauma of living
through real conspiracies all around us
— conspiracies among wealthy people,
their lobbyists, and lawmakers to bury
inconvenient facts and evidence of
wrongdoing (these conspiracies are
commonly known as “corruption”) — is
making people vulnerable to conspiracy
theories?  If it’s trauma and not
contagion — material conditions and not
ideology — that is making the difference
today and enabling a rise of repulsive
misinformation in the face of easily
observed facts, that doesn’t mean our
computer networks are blameless. They’re
still doing the heavy work of locating
vulnerable people and guiding them
through a series of ever-more-extreme
ideas and communities.  Belief in
conspiracy is a raging fire that has
done real damage and poses real danger
to our planet and species, from
epidemics kicked off by vaccine denial
to genocides kicked off by racist
conspiracies to planetary meltdown
caused by denial-inspired climate
inaction. Our world is on fire, and so
we have to put the fires out — to figure
out how to help people see the truth of
the world through the conspiracies
they’ve been confused by.  But
firefighting is reactive. We need fire
prevention. We need to strike at the
traumatic material conditions that make
people vulnerable to the contagion of
conspiracy. Here, too, tech has a role
to play.  There’s no shortage of
proposals to address this. From the EU’s
Terrorist Content Regulation, which
requires platforms to police and remove
“extremist” content, to the U.S.
proposals to force tech companies to spy
on their users and hold them liable for
their users’ bad speech, there’s a lot
of energy to force tech companies to
solve the problems they created.
There’s a critical piece missing from
the debate, though. All these solutions
assume that tech companies are a
fixture, that their dominance over the
internet is a permanent fact. Proposals
to replace Big Tech with a more
diffused, pluralistic internet are
nowhere to be found. Worse: The
“solutions” on the table today require
Big Tech to stay big because only the
very largest companies can afford to
implement the systems these laws demand.
Figuring out what we want our tech to
look like is crucial if we’re going to
get out of this mess. Today, we’re at a
crossroads where we’re trying to figure
out if we want to fix the Big Tech
companies that dominate our internet or
if we want to fix the internet itself by
unshackling it from Big Tech’s
stranglehold. We can’t do both, so we
have to choose.  I want us to choose
wisely. Taming Big Tech is integral to
fixing the internet, and for that, we
need digital rights activism.  Digital
rights activism, a quarter-century on
Digital rights activism is more than 30
years old now. The Electronic Frontier
Foundation turned 30 this year; the Free
Software Foundation launched in 1985.
For most of the history of the movement,
the most prominent criticism leveled
against it was that it was irrelevant:
The real activist causes were real-world
causes (think of the skepticism when
Finland declared broadband a human right
in 2010), and real-world activism was
shoe-leather activism (think of Malcolm
Gladwell’s contempt for “clicktivism”).
But as tech has grown more central to
our daily lives, these accusations of
irrelevance have given way first to
accusations of insincerity (“You only
care about tech because you’re shilling
for tech companies”) to accusations of
negligence (“Why didn’t you foresee that
tech could be such a destructive
force?”). But digital rights activism is
right where it’s always been: looking
out for the humans in a world where tech
is inexorably taking over.  The latest
version of this critique comes in the
form of “surveillance capitalism,” a
term coined by business professor
Shoshana Zuboff in her long and
influential 2019 book, The Age of
Surveillance Capitalism: The Fight for a
Human Future at the New Frontier of
Power. Zuboff argues that “surveillance
capitalism” is a unique creature of the
tech industry and that it is unlike any
other abusive commercial practice in
history, one that is “constituted by
unexpected and often illegible
mechanisms of extraction,
commodification, and control that
effectively exile persons from their own
behavior while producing new markets of
behavioral prediction and modification.
Surveillance capitalism challenges
democratic norms and departs in key ways
from the centuries-long evolution of
market capitalism.” It is a new and
deadly form of capitalism, a “rogue
capitalism,” and our lack of
understanding of its unique capabilities
and dangers represents an existential,
species-wide threat. She’s right that
capitalism today threatens our species,
and she’s right that tech poses unique
challenges to our species and
civilization, but she’s really wrong
about how tech is different and why it
threatens our species.  What’s more, I
think that her incorrect diagnosis will
lead us down a path that ends up making
Big Tech stronger, not weaker. We need
to take down Big Tech, and to do that,
we need to start by correctly
identifying the problem.  Tech
exceptionalism, then and now Early
critics of the digital rights movement —
perhaps best represented by campaigning
organizations like the Electronic
Frontier Foundation, the Free Software
Foundation, Public Knowledge, and others
that focused on preserving and enhancing
basic human rights in the digital realm
— damned activists for practicing “tech
exceptionalism.” Around the turn of the
millennium, serious people ridiculed any
claim that tech policy mattered in the
“real world.” Claims that tech rules had
implications for speech, association,
privacy, search and seizure, and
fundamental rights and equities were
treated as ridiculous, an elevation of
the concerns of sad nerds arguing about
Star Trek on bulletin board systems
above the struggles of the Freedom
Riders, Nelson Mandela, or the Warsaw
ghetto uprising.  In the decades since,
accusations of “tech exceptionalism”
have only sharpened as tech’s role in
everyday life has expanded: Now that
tech has infiltrated every corner of our
life and our online lives have been
monopolized by a handful of giants,
defenders of digital freedoms are
accused of carrying water for Big Tech,
providing cover for its self-interested
negligence (or worse, nefarious plots).
From my perspective, the digital rights
movement has remained stationary while
the rest of the world has moved. From
the earliest days, the movement’s
concern was users and the toolsmiths who
provided the code they needed to realize
their fundamental rights. Digital rights
activists only cared about companies to
the extent that companies were acting to
uphold users’ rights (or, just as often,
when companies were acting so foolishly
that they threatened to bring down new
rules that would also make it harder for
good actors to help users).  The
“surveillance capitalism” critique
recasts the digital rights movement in a
new light again: not as alarmists who
overestimate the importance of their
shiny toys nor as shills for big tech
but as serene deck-chair rearrangers
whose long-standing activism is a
liability because it makes them
incapable of perceiving novel threats as
they continue to fight the last
century’s tech battles.  But tech
exceptionalism is a sin no matter who
practices it.  Image for post Don’t
believe the hype You’ve probably heard
that “if you’re not paying for the
product, you’re the product.” As we’ll
see below, that’s true, if incomplete.
But what is absolutely true is that
ad-driven Big Tech’s customers are
advertisers, and what companies like
Google and Facebook sell is their
ability to convince you to buy stuff.
Big Tech’s product is persuasion. The
services — social media, search engines,
maps, messaging, and more — are delivery
systems for persuasion.  The fear of
surveillance capitalism starts from the
(correct) presumption that everything
Big Tech says about itself is probably a
lie. But the surveillance capitalism
critique makes an exception for the
claims Big Tech makes in its sales
literature — the breathless hype in the
pitches to potential advertisers online
and in ad-tech seminars about the
efficacy of its products: It assumes
that Big Tech is as good at influencing
us as they claim they are when they’re
selling influencing products to
credulous customers. That’s a mistake
because sales literature is not a
reliable indicator of a product’s
efficacy.  Surveillance capitalism
assumes that because advertisers buy a
lot of what Big Tech is selling, Big
Tech must be selling something real. But
Big Tech’s massive sales could just as
easily be the result of a popular
delusion or something even more
pernicious: monopolistic control over
our communications and commerce.  Being
watched changes your behavior, and not
for the better. It creates risks for our
social progress. Zuboff’s book features
beautifully wrought explanations of
these phenomena. But Zuboff also claims
that surveillance literally robs us of
our free will — that when our personal
data is mixed with machine learning, it
creates a system of persuasion so
devastating that we are helpless before
it. That is, Facebook uses an algorithm
to analyze the data it nonconsensually
extracts from your daily life and uses
it to customize your feed in ways that
get you to buy stuff. It is a
mind-control ray out of a 1950s comic
book, wielded by mad scientists whose
supercomputers guarantee them perpetual
and total world domination.  What is
persuasion?  To understand why you
shouldn’t worry about mind-control rays
— but why you should worry about
surveillance and Big Tech — we must
start by unpacking what we mean by
“persuasion.” Google, Facebook, and
other surveillance capitalists promise
their customers (the advertisers) that
if they use machine-learning tools
trained on unimaginably large data sets
of nonconsensually harvested personal
information, they will be able to
uncover ways to bypass the rational
faculties of the public and direct their
behavior, creating a stream of
purchases, votes, and other desired
outcomes.  The impact of dominance far
exceeds the impact of manipulation and
should be central to our analysis and
any remedies we seek.  But there’s
little evidence that this is happening.
Instead, the predictions that
surveillance capitalism delivers to its
customers are much less impressive.
Rather than finding ways to bypass our
rational faculties, surveillance
capitalists like Mark Zuckerberg mostly
do one or more of three things: 1.
Segmenting If you’re selling diapers,
you have better luck if you pitch them
to people in maternity wards. Not
everyone who enters or leaves a
maternity ward just had a baby, and not
everyone who just had a baby is in the
market for diapers. But having a baby is
a really reliable correlate of being in
the market for diapers, and being in a
maternity ward is highly correlated with
having a baby. Hence diaper ads around
maternity wards (and even pitchmen for
baby products, who haunt maternity wards
with baskets full of freebies).
Surveillance capitalism is segmenting
times a billion. Diaper vendors can go
way beyond people in maternity wards
(though they can do that, too, with
things like location-based mobile ads).
They can target you based on whether
you’re reading articles about
child-rearing, diapers, or a host of
other subjects, and data mining can
suggest unobvious keywords to advertise
against. They can target you based on
the articles you’ve recently read. They
can target you based on what you’ve
recently purchased. They can target you
based on whether you receive emails or
private messages about these subjects —
or even if you speak aloud about them
(though Facebook and the like
convincingly claim that’s not happening
— yet).  This is seriously creepy.  But
it’s not mind control.  It doesn’t
deprive you of your free will. It
doesn’t trick you.  Think of how
surveillance capitalism works in
politics. Surveillance capitalist
companies sell political operatives the
power to locate people who might be
receptive to their pitch. Candidates
campaigning on finance industry
corruption seek people struggling with
debt; candidates campaigning on
xenophobia seek out racists. Political
operatives have always targeted their
message whether their intentions were
honorable or not: Union organizers set
up pitches at factory gates, and white
supremacists hand out fliers at John
Birch Society meetings.  But this is an
inexact and thus wasteful practice. The
union organizer can’t know which worker
to approach on the way out of the
factory gates and may waste their time
on a covert John Birch Society member;
the white supremacist doesn’t know which
of the Birchers are so delusional that
making it to a meeting is as much as
they can manage and which ones might be
convinced to cross the country to carry
a tiki torch through the streets of
Charlottesville, Virginia.  Because
targeting improves the yields on
political pitches, it can accelerate the
pace of political upheaval by making it
possible for everyone who has secretly
wished for the toppling of an autocrat —
or just an 11-term incumbent politician
— to find everyone else who feels the
same way at very low cost. This has been
critical to the rapid crystallization of
recent political movements including
Black Lives Matter and Occupy Wall
Street as well as less savory players
like the far-right white nationalist
movements that marched in
Charlottesville.  It’s important to
differentiate this kind of political
organizing from influence campaigns;
finding people who secretly agree with
you isn’t the same as convincing people
to agree with you. The rise of phenomena
like nonbinary or otherwise
nonconforming gender identities is often
characterized by reactionaries as the
result of online brainwashing campaigns
that convince impressionable people that
they have been secretly queer all along.
But the personal accounts of those who
have come out tell a different story
where people who long harbored a secret
about their gender were emboldened by
others coming forward and where people
who knew that they were different but
lacked a vocabulary for discussing that
difference learned the right words from
these low-cost means of finding people
and learning about their ideas.  2.
Deception Lies and fraud are pernicious,
and surveillance capitalism supercharges
them through targeting. If you want to
sell a fraudulent payday loan or
subprime mortgage, surveillance
capitalism can help you find people who
are both desperate and unsophisticated
and thus receptive to your pitch. This
accounts for the rise of many phenomena,
like multilevel marketing schemes, in
which deceptive claims about potential
earnings and the efficacy of sales
techniques are targeted at desperate
people by advertising against search
queries that indicate, for example,
someone struggling with ill-advised
loans.  Surveillance capitalism also
abets fraud by making it easy to locate
other people who have been similarly
deceived, forming a community of people
who reinforce one another’s false
beliefs. Think of the forums where
people who are being victimized by
multilevel marketing frauds gather to
trade tips on how to improve their luck
in peddling the product.  Sometimes,
online deception involves replacing
someone’s correct beliefs with incorrect
ones, as it does in the anti-vaccination
movement, whose victims are often people
who start out believing in vaccines but
are convinced by seemingly plausible
evidence that leads them into the false
belief that vaccines are harmful.  But
it’s much more common for fraud to
succeed when it doesn’t have to displace
a true belief. When my daughter
contracted head lice at daycare, one of
the daycare workers told me I could get
rid of them by treating her hair and
scalp with olive oil. I didn’t know
anything about head lice, and I assumed
that the daycare worker did, so I tried
it (it didn’t work, and it doesn’t
work). It’s easy to end up with false
beliefs when you simply don’t know any
better and when those beliefs are
conveyed by someone who seems to know
what they’re doing.  This is pernicious
and difficult — and it’s also the kind
of thing the internet can help guard
against by making true information
available, especially in a form that
exposes the underlying deliberations
among parties with sharply divergent
views, such as Wikipedia. But it’s not
brainwashing; it’s fraud. In the
majority of cases, the victims of these
fraud campaigns have an informational
void filled in the customary way, by
consulting a seemingly reliable source.
If I look up the length of the Brooklyn
Bridge and learn that it is 5,800 feet
long, but in reality, it is 5,989 feet
long, the underlying deception is a
problem, but it’s a problem with a
simple remedy. It’s a very different
problem from the anti-vax issue in which
someone’s true belief is displaced by a
false one by means of sophisticated
persuasion.  3. Domination Surveillance
capitalism is the result of monopoly.
Monopoly is the cause, and surveillance
capitalism and its negative outcomes are
the effects of monopoly. I’ll get into
this in depth later, but for now,
suffice it to say that the tech industry
has grown up with a radical theory of
antitrust that has allowed companies to
grow by merging with their rivals,
buying up their nascent competitors, and
expanding to control whole market
verticals.  One example of how
monopolism aids in persuasion is through
dominance: Google makes editorial
decisions about its algorithms that
determine the sort order of the
responses to our queries. If a cabal of
fraudsters have set out to trick the
world into thinking that the Brooklyn
Bridge is 5,800 feet long, and if Google
gives a high search rank to this group
in response to queries like “How long is
the Brooklyn Bridge?” then the first
eight or 10 screens’ worth of Google
results could be wrong. And since most
people don’t go beyond the first couple
of results — let alone the first page of
results — Google’s choice means that
many people will be deceived.  Google’s
dominance over search — more than 86% of
web searches are performed through
Google — means that the way it orders
its search results has an outsized
effect on public beliefs. Ironically,
Google claims this is why it can’t
afford to have any transparency in its
algorithm design: Google’s search
dominance makes the results of its
sorting too important to risk telling
the world how it arrives at those
results lest some bad actor discover a
flaw in the ranking system and exploit
it to push its point of view to the top
of the search results. There’s an
obvious remedy to a company that is too
big to audit: break it up into smaller
pieces.  Zuboff calls surveillance
capitalism a “rogue capitalism” whose
data-hoarding and machine-learning
techniques rob us of our free will. But
influence campaigns that seek to
displace existing, correct beliefs with
false ones have an effect that is small
and temporary while monopolistic
dominance over informational systems has
massive, enduring effects. Controlling
the results to the world’s search
queries means controlling access both to
arguments and their rebuttals and, thus,
control over much of the world’s
beliefs. If our concern is how
corporations are foreclosing on our
ability to make up our own minds and
determine our own futures, the impact of
dominance far exceeds the impact of
manipulation and should be central to
our analysis and any remedies we seek.
4. Bypassing our rational faculties This
is the good stuff: using machine
learning, “dark patterns,” engagement
hacking, and other techniques to get us
to do things that run counter to our
better judgment. This is mind control.
Some of these techniques have proven
devastatingly effective (if only in the
short term). The use of countdown timers
on a purchase completion page can create
a sense of urgency that causes you to
ignore the nagging internal voice
suggesting that you should shop around
or sleep on your decision. The use of
people from your social graph in ads can
provide “social proof” that a purchase
is worth making. Even the auction system
pioneered by eBay is calculated to play
on our cognitive blind spots, letting us
feel like we “own” something because we
bid on it, thus encouraging us to bid
again when we are outbid to ensure that
“our” things stay ours.  Games are
extraordinarily good at this. “Free to
play” games manipulate us through many
techniques, such as presenting players
with a series of smoothly escalating
challenges that create a sense of
mastery and accomplishment but which
sharply transition into a set of
challenges that are impossible to
overcome without paid upgrades. Add some
social proof to the mix — a stream of
notifications about how well your
friends are faring — and before you know
it, you’re buying virtual power-ups to
get to the next level.  Companies have
risen and fallen on these techniques,
and the “fallen” part is worth paying
attention to. In general, living things
adapt to stimulus: Something that is
very compelling or noteworthy when you
first encounter it fades with repetition
until you stop noticing it altogether.
Consider the refrigerator hum that
irritates you when it starts up but
disappears into the background so
thoroughly that you only notice it when
it stops again.  That’s why behavioral
conditioning uses “intermittent
reinforcement schedules.” Instead of
giving you a steady drip of
encouragement or setbacks, games and
gamified services scatter rewards on a
randomized schedule — often enough to
keep you interested and random enough
that you can never quite find the
pattern that would make it boring.
Intermittent reinforcement is a powerful
behavioral tool, but it also represents
a collective action problem for
surveillance capitalism. The “engagement
techniques” invented by the behaviorists
of surveillance capitalist companies are
quickly copied across the whole sector
so that what starts as a mysteriously
compelling fillip in the design of a
service—like “pull to refresh” or alerts
when someone likes your posts or side
quests that your characters get invited
to while in the midst of main
quests—quickly becomes dully ubiquitous.
The impossible-to-nail-down nonpattern
of randomized drips from your phone
becomes a grey-noise wall of sound as
every single app and site starts to make
use of whatever seems to be working at
the time.  From the surveillance
capitalist’s point of view, our adaptive
capacity is like a harmful bacterium
that deprives it of its food source —
our attention — and novel techniques for
snagging that attention are like new
antibiotics that can be used to breach
our defenses and destroy our
self-determination. And there are
techniques like that. Who can forget the
Great Zynga Epidemic, when all of our
friends were caught in FarmVille’s
endless, mindless dopamine loops? But
every new attention-commanding technique
is jumped on by the whole industry and
used so indiscriminately that antibiotic
resistance sets in. Given enough
repetition, almost all of us develop
immunity to even the most powerful
techniques — by 2013, two years after
Zynga’s peak, its user base had halved.
Not everyone, of course. Some people
never adapt to stimulus, just as some
people never stop hearing the hum of the
refrigerator. This is why most people
who are exposed to slot machines play
them for a while and then move on while
a small and tragic minority liquidate
their kids’ college funds, buy adult
diapers, and position themselves in
front of a machine until they collapse.
But surveillance capitalism’s margins on
behavioral modification suck. Tripling
the rate at which someone buys a widget
sounds great unless the base rate is way
less than 1% with an improved rate of…
still less than 1%. Even penny slot
machines pull down pennies for every
spin while surveillance capitalism rakes
in infinitesimal penny fractions.  Slot
machines’ high returns mean that they
can be profitable just by draining the
fortunes of the small rump of people who
are pathologically vulnerable to them
and unable to adapt to their tricks. But
surveillance capitalism can’t survive on
the fractional pennies it brings down
from that vulnerable sliver — that’s
why, after the Great Zynga Epidemic had
finally burned itself out, the small
number of still-addicted players left
behind couldn’t sustain it as a global
phenomenon. And new powerful attention
weapons aren’t easy to find, as is
evidenced by the long years since the
last time Zynga had a hit. Despite the
hundreds of millions of dollars that
Zynga has to spend on developing new
tools to blast through our adaptation,
it has never managed to repeat the lucky
accident that let it snag so much of our
attention for a brief moment in 2009.
Powerhouses like Supercell have fared a
little better, but they are rare and
throw away many failures for every
success.  The vulnerability of small
segments of the population to dramatic,
efficient corporate manipulation is a
real concern that’s worthy of our
attention and energy. But it’s not an
existential threat to society.
